{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtV73eojPRNL"
   },
   "source": [
    "# Week 5: Introduction to Supervised Machine Learning\n",
    "\n",
    "\n",
    "This week will introduce you to fundamental machine learning (ML) concepts. By the end of this module, you will understand basic machine learning terminology as well as know how to train and evaluate an ML model. In the pre-module, you learned what Machine Learning and were introduced to the Pima Diabetes case study. In this module, we will continue with analysing the cause of diabetes using *Supervised Machine Learning*.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJJkyHpHQ9bq"
   },
   "source": [
    "## Supervised ML\n",
    "\n",
    "Supervised Machine Learning is a type of machine learning where the model is trained on a **labeled dataset**, meaning each sample comes with an input-output pair. The model learns to map inputs (predictor variables AKA features) to the correct output (labels AKA response variables). This type of learning is common in tasks like medical diagnosis, where patient data is labeled with specific health conditions.\n",
    "\n",
    "There are two primary supervised machine learning tasks, classification and regression:\n",
    "\n",
    "* **Classification** is a supervised learning task that involves predicting discrete labels for input data. For example, a classification model might be trained to identify images of animals as either \"cat,\" \"dog,\" or \"bird.\" Classification is widely used in applications like medical diagnostics, where the goal might be to classify cells as cancerous or non-cancerous.\n",
    "\n",
    "* **Regression** is another type of supervised learning task, but unlike classification, it involves predicting continuous, numerical outputs rather than discrete categories. For instance, it might predict a patient's blood pressure based on their age, weight, and lifestyle factors.\n",
    "\n",
    "For the following notebooks, we will primarily focus on classification tasks, but know that the concepts presented carry over to regression tasks as well. Below, we focus on the model training and model evaluation steps of the machine learning pipeline.\n",
    "\n",
    "![fcall](fcall.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzhDNnNkUVif"
   },
   "source": [
    "### Case Study: Predicting Diabetes Risk in Pima Indian Women\n",
    "\n",
    "As a reminder, the Pima Diabetes case study consists of a dataset with 768 records, with each instance containing eight attributes and a target variable. Each record represents one patient and includes the following attributes:\n",
    "\n",
    "* Pregnancies: Number of times the patient has been pregnant.\n",
    "* Glucose: Plasma glucose concentration over two hours in an oral glucose tolerance test.\n",
    "* Blood Pressure: Diastolic blood pressure (mm Hg).\n",
    "* Skin Thickness: Triceps skinfold thickness (mm).\n",
    "* Insulin: Two-hour serum insulin (mu U/ml).\n",
    "* BMI: Body mass index (weight in kg/(height in m)^2).\n",
    "* Diabetes Pedigree Function: A function that scores likelihood of diabetes based on family history.\n",
    "* Age: Patient's age (years).\n",
    "\n",
    "\n",
    "**Using these pieces of information, our goal is to predict whether or not the patient had diabetes. In other words, this is a *classification* problem.**\n",
    "\n",
    "\n",
    "Below, we load in the dataset from an online source where `X` are the measurements taken by the researchers, and `y` contains whether or not each a positive diagnosis was given. Each row in the data represents one sample. For this module, we will convert `y` into a binary variable where 1 represents a patient had diabetes, and 0 means a patient does not have diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qN-End08PF0i"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# we fetch the dataset from https://www.openml.org/search?type=data&status=active&id=37\n",
    "X,y = fetch_openml(data_id = 37, as_frame = True, return_X_y = True)\n",
    "\n",
    "# convert tested_positive and tested_negative to 1 and 0\n",
    "y = (y == 'tested_positive').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7jPArGlZ1tr"
   },
   "source": [
    "\n",
    "As stated before  our goal is to accurately predict whether or not a given patient developed diabetes. If we can do this task *accurately*, then in the future we may be able to help patients proactively rather than treat them after they develop diabetes:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Correct Predictions}}{\\text{All Predictions}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pst3Gq2Qj-CY"
   },
   "source": [
    "---\n",
    "##### **Q1: Copy your rules from the pre-module. What is the accuracy of your rules? Do you think this is acceptable for clinical usage?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tn34mXw3kC1q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T829Myr8kC68"
   },
   "source": [
    "*Your Answer Here*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwS5JHGvo9iR"
   },
   "source": [
    "Chances are that the manual rules you created do not adequately predict whether or not someone has diabetes. This is understandable as there are a lot of features and samples, which makes manually identifying potential reasons for diabetes is difficult. **Therefore, we will train an ML model to do this for us.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kfxNYj7j7YP"
   },
   "source": [
    "## Model Training\n",
    "![fc3](fc3.png)\n",
    "### What is a model?\n",
    "\n",
    "In the world of machine learning, A **model** is an **computer algorithm** that calculates an output based on input(s) from a dataset through calculations using learned **parameters**. These parameters allow it to make predictions on previously unseen data.\n",
    "\n",
    "A machine learning model can perform such tasks by having it **trained** with a large dataset (a process also known as **fitting** a model). Training a model is the process of teaching a model to recognize patterns or rules by using data. During training, the model makes predictions with inputs, and then calculates the error between its prediction and the true answer. It then adjusts its internal parameters to get better at making a guess. More specifically, the training process is as follows:\n",
    "\n",
    "The model begins with a set of initial weights, typically assigned randomly. These weights represent the model's initial state before any learning occurs, similar to a \"blank slate\" or initial knowledge base.\n",
    "\n",
    "1. We pass all points from the dataset \\( $x$ \\) into the model.\n",
    "2. The model processes this input, performing computations based on \\( $x$ \\) and its current weights, to produce predictions, denoted as \\( $\\hat{y}$ \\).\n",
    "3. We then calculate the error (the opposite of accuracy) of all the predictions the model made.\n",
    "4. By looking at what the model got right and wrong, we can adjust the relevant parameters of the model so that the next set of predictions is more accuracy.\n",
    "5. We then repeat steps 1-4 until the error stops reducing, or we reach some stopping conditions (ex. we hit a limit on the number of guesses).  \n",
    "\n",
    "This iterative process allows the model to gradually refine its weights, thereby improving its predictions as it learns from the data. Think of it like a student. By doing a lot of homework questions, a student can learn what answers are correct to given questions, and what answers are incorrect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Kx-1-1EczOc"
   },
   "source": [
    "\n",
    "#### Fitting a Logistic Regression Model\n",
    "\n",
    "One machine learning algorithm that we can use is *Logistic Regression*. You have already seen this model in Week 3, but as a refresher, Logisitic Regression makes predictions by adding the inputs together with different weights:\n",
    "\n",
    "$$\n",
    "\\hat{y} = b + w_1x_1 + w_2x_2 + \\dots + w_nx_n\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- \\( $b$ \\) is the intercept or bias term\n",
    "- \\( $w_1, w_2, \\dots, w_n$ \\) are the weights associated with each feature, and\n",
    "- \\( $x_1, x_2, \\dots, x_n$ \\) are the feature values.\n",
    "\n",
    "If the result of the sum is above zero, we predict the positive class (1). Otherwise we predict the negative class (0).\n",
    "\n",
    "In this model the different weights as well as the bias term are the *parameters* that are learned in the model. To put it in context of the training process above:\n",
    "\n",
    "1. Given our datapoints $x$, will calculate $\\hat{y}$ through the above question\n",
    "2. We then calculate whether or not we got the prediction correctly.\n",
    "3. Depending on our error (ex. did we overpredict the true values, underpredict the true values, etc.) we adjust each weight either up or down.\n",
    "4. We repeat steps 1-3 multiple times, stopping when the model stops improving (or if we hit the limit of iterations we set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh74sfTikPWI"
   },
   "source": [
    "![training_flowchart](model_training_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SjXIeI6bEm-"
   },
   "source": [
    "#### SciKit-Learn\n",
    "Now luckily, we don't need to manually code the training procedure for many models. Instead, we can use a package called SciKit-Learn AKA `sklearn`. This is a Python library that contains many useful machine learning tools such as:\n",
    "* Loading in common datasets (Seen above).\n",
    "* Tools to process your data.\n",
    "* Code to train various models, including code to fit a Logistic Regression model.\n",
    "* Code to evaluate your trained models.\n",
    "\n",
    "\n",
    "In the cell below, we train and evaluate a Logistic Regression model. This is a little bit different than the previous way we fit LR in module 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3aMmIZaclH1"
   },
   "outputs": [],
   "source": [
    "# import the LogisticRegression class.\n",
    "# This contains all code needed to train LR\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create an instance of the LR model.\n",
    "# By setting max_iter to 30, we say that we want to do steps 1-3 at most 30 times.\n",
    "model = LogisticRegression(solver = 'liblinear', max_iter = 30)\n",
    "\n",
    "# fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# measure what proportion of the predictions we got correct.\n",
    "\n",
    "accuracy = np.sum(predictions == y) / len(y)\n",
    "print(f'Accuracy: {accuracy*100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use functions from `sklearn` to calculate the accuracy of our model. The `accuracy_score` function from `sklearn.metrics` calculates the accuracy of the model by comparing the predicted values to the true values. The function takes in two arguments: the true values and the predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100: .4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tz8O6jSDUqE4"
   },
   "source": [
    "---\n",
    "\n",
    "##### **Q2: Compare the accuracy of Logistic Regression to your hand-crafted rules. Which did better?**\n",
    "\n",
    "*Your Answer Here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5rbjKsAfTCT"
   },
   "source": [
    "---\n",
    "\n",
    "##### **Q3: Try running Logistic Regression with 10 different values of `max_iter` that are smaller than 30 and 10 that are larger than 30. Plot out the model accuracy by the number of iterations. What do you observe as you increase the number of iterations? Does the training accuracy stop improving at some point?**\n",
    "\n",
    "> NOTE: If you get `ConvergenceWarning`, ignore it for now you're doing fine :). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a74P3WRfTJu"
   },
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ply2gRQpfTUv"
   },
   "source": [
    "*Your Answer Here*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mQ_57nvmCDc"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "![fc4](fc4.png)\n",
    "\n",
    "Imagine you're a doctor trying to learn if someone might have diabetes based on things like their age, weight, or blood sugar levels. To get really good at predicting this, you practice with records from patients you've already seen before, where you know if they ended up having diabetes or not.\n",
    "\n",
    "But if you only checked how good you were using those same patients, you might not really know if you're good at guessing for new people you haven't met. Maybe you're just getting used to those specific patients and learning things about them rather than truly understanding the signs of diabetes.\n",
    "\n",
    "Our machine learning model's can fall into the same fallacy. Often evaluating our model on the same data that was used to train them can result in a more optimistic view of the model's performance. **To handle this, we will actually withold some data from the model** by creating two different by randomly splitting the data into two different sets:\n",
    "\n",
    "1. Training set: This is the dataset we give the model to learn from. Think of it as homework given to students. The model can practice getting these answers correctly (aka training).\n",
    "2. Test set: This is data the model has not seen. Think of it as the exam. Student's used homework questions to learn the concepts (training), now we evaluate how well they learned patterns and trends by giving them questions they have not\n",
    "\n",
    "Ideally, we want a model that does well on both the training AND testing set.\n",
    "\n",
    "In the cell below, we split the data using the `train_test_split` method provided by `sklearn`. We allocate 80% of the data to the training set, and 20% of the data to the testing set (aka the exam).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZpRgK9WiBhc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4khUit2iG4D"
   },
   "source": [
    "---\n",
    "\n",
    "##### **Q4: Train a model on the train set, make predictions for both the train and test set, and report the accuracy on both sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ygJcwhrdvne"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# create model class\n",
    "\n",
    "# Train model on the train set\n",
    "\n",
    "# make predictions for train set\n",
    "\n",
    "# make predictions for the test set\n",
    "\n",
    "# Calculate accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8UmiT5mWpB8"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlrNZKY3mYCk"
   },
   "source": [
    "### Measures beyond Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd5nVsOElhGZ"
   },
   "source": [
    "While accuracy is a good measure of how many predictions the model is getting correct, we often care about the *type* of correct and incorrect predictions. More specifically, we care about True Positives, True Negatives, False Positives, and False Negatives:\n",
    "\n",
    "* False positive (FP): predicted positive, but the true label was actually negative. (Type I error)\n",
    "* False negative (FN): predicted negative, but the true label was actually positive. (Type II error)\n",
    "* True positive (TP): predicted positive, and the true label was indeed positive.\n",
    "* True negative (TN): predicted negative, and the true label was indeed negative.\n",
    "\n",
    "Using this terminology, we can improve our definition of Accuracy:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} =\\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XT1HP_XVQRHw"
   },
   "source": [
    "---\n",
    "##### **Q5: Calculate the True Positives, True Negatives, False Positives, and False negatives of your model predictions on the train set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPKxFzo-QcjV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY_KhxK6QcuG"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObQHbMgCQPDc"
   },
   "source": [
    "\n",
    "Apart from accuracy, other common ways to measure the performance of your classification model is *Precision* and *Recall.*\n",
    "\n",
    "\n",
    "In machine learning, \"precision\" refers to a metric that measures the **proportion of positive predictions made by a model that are actually correct,**. This is basically asking \"What portion of people are predicted to have diabetes actually has diabetes?\"\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBXkR62go7xl"
   },
   "source": [
    "\"Recall\" is a metric that measures how well a model can identify all relevant positive instances within a dataset. This is basically asking \"Of all the people that have diabetes, how many did the model actually predict.\"\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP+FN}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMC34GYrplRv"
   },
   "source": [
    "---\n",
    "\n",
    "##### **Q6: Calculate the train and test precision and recall of your model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hl-WIBOApkmc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fPfjHoNpjuW"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWIDN83Nijdz"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this module, we introduced the fundamentals of training and evaluating a machine learning (ML) model. By iteratively making guesses and adjusting itself based on those guesses, an ML model can learn rules and patterns in the data that are useful in making predictions. In the next model, we will learn about more models and further our knowledge in how to use machine learning for biological applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTC3EnX7ko8H"
   },
   "source": [
    "## Graded Questions\n",
    "\n",
    "In this set of graded questions, you will train a Logistic Regression model on the Heart Failures dataset from the prior weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8noRpETlA1n"
   },
   "source": [
    "---\n",
    "\n",
    "##### **GQ1: Read in the heart failures dataset (`hf_data_tut.csv`) (1pt) and split the predictor variables (features) from the labels (response variable) (1pt).**\n",
    "\n",
    "> HINT: Look at your work from Week 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FF6eOB_hnwzY"
   },
   "outputs": [],
   "source": [
    "# Your Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Gm5_C31nxAf"
   },
   "source": [
    "---\n",
    "##### **GQ2: Train a Logistic Regression model on *all* the data (1pt). What is the accuracy (1pt)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jDF8S4ToeqG"
   },
   "outputs": [],
   "source": [
    "# Your Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifOtJDeYoA15"
   },
   "source": [
    "---\n",
    "\n",
    "##### **GQ3: Split the dataset into a train and test set and retrain your model (1pt). What is the train and test accuracy (2pt), precision (2pt), and recall (2pt)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7RoqHGsodUS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
