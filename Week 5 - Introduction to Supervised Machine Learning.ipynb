{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtV73eojPRNL"
   },
   "source": [
    "# Week 5: Introduction to Supervised Machine Learning\n",
    "\n",
    "\n",
    "This week will introduce you to fundamental machine learning (ML) concepts. By the end of this module, you will understand basic machine learning terminology as well as know how to train and evaluate an ML model. In the pre-module, you learned about the difference between Machine Learning and Artificial intelligence and were introduced to the Pima Diabetes case study. In this module, we will continue with analysing the cause of diabetes using *Supervised Machine Learning*.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJJkyHpHQ9bq"
   },
   "source": [
    "## Supervised ML\n",
    "\n",
    "Supervised Machine Learning is a type of machine learning where the model is trained on a **labeled dataset**, meaning each sample comes with an input-output pair. The model learns to map inputs (predictor variables AKA features  AKA attributes) to the correct output (labels AKA response variables). This type of learning is common in tasks like medical diagnosis, where patient data is labeled with specific health conditions.\n",
    "\n",
    "There are two primary supervised machine learning tasks, classification and regression:\n",
    "\n",
    "* **Classification** is a supervised learning task that involves predicting discrete labels for input data. For example, a classification model might be trained to identify images of animals as either \"cat,\" \"dog,\" or \"bird.\" Classification is widely used in applications like medical diagnostics, where the goal might be to classify cells as cancerous or non-cancerous.\n",
    "\n",
    "* **Regression** is another type of supervised learning task, but unlike classification, it involves predicting continuous, numerical outputs rather than discrete categories. For instance, it might predict a patient's blood pressure based on their age, weight, and lifestyle factors.\n",
    "\n",
    "For the following notebooks, we will primarily focus on classification tasks, but know that the concepts presented carry over to regression tasks as well. Below, we focus on the model training and model evaluation steps of the machine learning pipeline.\n",
    "\n",
    "![fcall](fcall.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzhDNnNkUVif"
   },
   "source": [
    "### Case Study: Predicting Diabetes Risk in Pima Indian Women\n",
    "\n",
    "As a reminder, the Pima Diabetes case study consists of a dataset with 768 records, with each instance containing eight attributes and a target variable. Each record represents one patient and includes the following attributes:\n",
    "\n",
    "* Pregnancies: Number of times the patient has been pregnant.\n",
    "* Glucose: Plasma glucose concentration over two hours in an oral glucose tolerance test.\n",
    "* Blood Pressure: Diastolic blood pressure (mm Hg).\n",
    "* Skin Thickness: Triceps skinfold thickness (mm).\n",
    "* Insulin: Two-hour serum insulin (mu U/ml).\n",
    "* BMI: Body mass index (weight in kg/(height in m)^2).\n",
    "* Diabetes Pedigree Function: A function that scores likelihood of diabetes based on family history.\n",
    "* Age: Patient's age (years).\n",
    "\n",
    "\n",
    "**Using these pieces of information, our goal is to predict whether or not the patient had diabetes. In other words, this is a *classification* problem.**\n",
    "\n",
    "\n",
    "Below, we load in the dataset from an online source where `X` are the measurements taken by the researchers, and `y` contains whether or not each a positive diagnosis was given. Each row in the data represents one sample. For this module, we will convert `y` into a binary variable where 1 represents a patient had diabetes, and 0 means a patient does not have diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qN-End08PF0i"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# we fetch the dataset from https://www.openml.org/search?type=data&status=active&id=37\n",
    "X,y = fetch_openml(data_id = 37, as_frame = True, return_X_y = True)\n",
    "\n",
    "# convert tested_positive and tested_negative to 1 and 0\n",
    "y = (y == 'tested_positive').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7jPArGlZ1tr"
   },
   "source": [
    "An important aspect of any classification task is accuracy, that is, how many of the total predictions made by a model are correct predictions. Our goal for this example is to, as accurately as possible, predict whether or not a given patient developed diabetes. If we can perform this task accurately, then we may be able to help patients proactively before they develop diabetes: \n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Correct Predictions}}{\\text{All Predictions}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pst3Gq2Qj-CY"
   },
   "source": [
    "---\n",
    "##### **Q1: Copy your rules from the pre-module. What is the accuracy of your rules? Do you think this is acceptable for clinical usage?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tn34mXw3kC1q"
   },
   "outputs": [],
   "source": [
    "## Complete the code below\n",
    "\n",
    "# copy the rule you created from the pre-module \n",
    "# and subset the data into predicted_positive_cases and predicted_negative_cases\n",
    "predicted_positive_cases = ...\n",
    "predicted_negative_cases = ...\n",
    "\n",
    "# determine the number of positive cases within your predicted_positive_cases subset\n",
    "positive_cases_captured = ...\n",
    "# determine the number of negative cases within your predicted_negative_cases subset\n",
    "nagative_cases_captured = ...\n",
    "\n",
    "# sum all accurate predicitions and dived by the total number of predicitions made\n",
    "accuracy = ...\n",
    "print(f\"Accuracy of my rule: {accuracy}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T829Myr8kC68"
   },
   "source": [
    "*Your Answer Here*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwS5JHGvo9iR"
   },
   "source": [
    "Chances are that the manual rules you created do not adequately predict whether an individual has diabetes. This is understandable given the high number of features and samples involved, making it challenging to manually identify potential causes of diabetes. **Therefore, we will train an ML model to do this for us.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kfxNYj7j7YP"
   },
   "source": [
    "## Model Training\n",
    "![fc3](fc3.png)\n",
    "### What is a model?\n",
    "\n",
    "In the realm of machine learning, A **model** is a computer **algorithm** that generates an output based on input(s) from a dataset by performing calculations using learned **parameters**. These parameters enable the model to make predictions on previously unseen data.\n",
    "\n",
    "A machine learning model can perform such tasks by being **trained** with a large dataset, a process also known as **fitting** a model. Training a model involves teaching it to recognize patterns or rules by using data. During training, the model makes predictions with inputs, and then calculates the error between its prediction and the actual outcome. It then adjusts its internal parameters to improve its accuracy. The training process can be detailed  as follows:\n",
    "\n",
    "The model begins with a set of initial weights, typically assigned randomly. These weights represent the model's initial state before any learning occurs, similar to a \"blank slate\" or initial knowledge base.\n",
    "\n",
    "1. We input all data points \\( $x$ \\) from the dataset into the model.\n",
    "2. The model processes this input, performing computations based on \\( $x$ \\) and its current weights, to produce predictions, denoted as \\( $\\hat{y}$ \\).\n",
    "3. We then calculate the error (the opposite of accuracy) of all predictions made by the model.\n",
    "4. By analyzing the modelâ€™s correct and incorrect predictions, we can adjust the relevant parameters to improve  accuracy.\n",
    "5. We then repeat steps 1-4 until the error stops decreasing, or we reach predefined  stopping conditions (e.g. we hit a limit on the number of iterations).  \n",
    "\n",
    "This iterative process allows the model to gradually refine its weights, thereby improving its predictions as it learns from the data. Think of it like a student. By solving  numerous problem sets, you can achieve better accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Kx-1-1EczOc"
   },
   "source": [
    "\n",
    "#### Fitting a Logistic Regression Model\n",
    "\n",
    "One machine learning algorithm that we can use is *Logistic Regression*. You have already seen this model in Week 3, but as a refresher, Logisitic Regression makes predictions by adding the inputs together with different weights:\n",
    "\n",
    "$$\n",
    "\\hat{y} = b + w_1x_1 + w_2x_2 + \\dots + w_nx_n\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- \\( $b$ \\) is the intercept or bias term\n",
    "- \\( $w_1, w_2, \\dots, w_n$ \\) are the weights associated with each feature, and\n",
    "- \\( $x_1, x_2, \\dots, x_n$ \\) are the feature values.\n",
    "\n",
    "If the result of the sum is above zero, we predict the positive class (1). Otherwise we predict the negative class (0).\n",
    "\n",
    "In this model the various weights as well as the bias term are the *parameters* that the model learns. Now to put this training process into the context of the Diabetes Risk dataset:\n",
    "\n",
    "1. Given our datapoints from the Diabetes Risk dataset $x$, we can calculate $\\hat{y}$ through the rule we previously created in the pre-module, or something similar to this.\n",
    "2. We can then determine whether or not we got the prediction correct based on the value of $\\hat{y}$.\n",
    "3. Depending on our error (ex. did we overpredict the true values, underpredict the true values, etc.) we can adjust each weight either up or down.\n",
    "4. We repeat steps 1-3 multiple times, stopping when the model stops improving (or if we hit the limit of iterations we set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh74sfTikPWI"
   },
   "source": [
    "![training_flowchart](model_training_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SjXIeI6bEm-"
   },
   "source": [
    "#### SciKit-Learn\n",
    "Now luckily, we don't need to manually code the training procedure for many models. Instead, we can use a package called SciKit-Learn AKA `sklearn`. This is a Python library that contains many useful machine learning tools such as:\n",
    "* Loading in common datasets (Seen above).\n",
    "* Tools to process your data.\n",
    "* Code to train various models, including code to fit a Logistic Regression model.\n",
    "* Code to evaluate your trained models.\n",
    "\n",
    "\n",
    "In the cell below, we train and evaluate a Logistic Regression (LR) model. This is slightly different than the previous way we fit LR in module 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3aMmIZaclH1"
   },
   "outputs": [],
   "source": [
    "# import the LogisticRegression class.\n",
    "# This contains all code needed to train LR\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create an instance of the LR model.\n",
    "# By setting max_iter to 30, we say that we want to do steps 1-3 at most 30 times.\n",
    "model = LogisticRegression(solver = 'liblinear', max_iter = 30)\n",
    "\n",
    "# fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# measure what proportion of the predictions we got correct.\n",
    "accuracy = np.sum(predictions == y) / len(y)\n",
    "print(f'Accuracy: {accuracy*100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use functions from `sklearn` to calculate the accuracy of our model. The `accuracy_score` function from `sklearn.metrics` calculates the accuracy of the model by comparing the predicted values to the true values. The function takes in two arguments: the true values and the predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100: .4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tz8O6jSDUqE4"
   },
   "source": [
    "---\n",
    "\n",
    "##### **Q2: Compare the accuracy of Logistic Regression to your hand-crafted rules. Which did better?**\n",
    "\n",
    "*Your Answer Here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5rbjKsAfTCT"
   },
   "source": [
    "---\n",
    "\n",
    "##### **Q3: Try running Logistic Regression with 10 different values of `max_iter` that are smaller than 30 and 10 that are larger than 30. Plot out the model accuracy by the number of iterations. What do you observe as you increase the number of iterations? Does the training accuracy stop improving at some point?**\n",
    "\n",
    "> NOTE: If you get `ConvergenceWarning`, ignore it for now you're doing fine :). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a74P3WRfTJu"
   },
   "outputs": [],
   "source": [
    "## Complete the code below\n",
    "\n",
    "# initalize a variable to store your results\n",
    "results = []\n",
    "\n",
    "# list all max_iter values to iterate through, typed out\n",
    "max_iter_list = ...\n",
    "\n",
    "# use a for loop to iterate through all max_iter values\n",
    "for max_iter_test in max_iter_list:\n",
    "    # create an instance of the LR model. be sure to set max_iter = max_iter_test\n",
    "    model = ...\n",
    "    # fit the model to the data\n",
    "\n",
    "    # make predictions\n",
    "\n",
    "    # measure the accuracy\n",
    "    \n",
    "    # append your current result to your results list\n",
    "\n",
    "# plot your max_iter_list and results list as a scatterplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ply2gRQpfTUv"
   },
   "source": [
    "*Your Answer Here*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mQ_57nvmCDc"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "![fc4](fc4.png)\n",
    "\n",
    "Imagine you're a doctor trying to learn if someone might have diabetes based on parameters like their age, weight, or blood sugar levels. To improve your prediction, you practice with records from patients you've already seen before, where you know if they ended up having diabetes or not.\n",
    "\n",
    "However, if you only evaluate your performance using the same patients, you may not accurately determine your ability to predict outcomes for new individuals you haven't encountered. Maybe you're just getting used to those specific patients and learning things about them rather than truly understanding the signs of diabetes.\n",
    "\n",
    "Our machine learning model's can fall into the same fallacy. Often evaluating our model on the same data that was used to train them can result in a more optimistic view of the model's performance. **To handle this, we will actually withold some data from the model** by randomly splitting the data into two different sets:\n",
    "\n",
    "1. This dataset is provided to the model for learning purposes, similar to homework given to students. The model practices and improves by correctly answering these questions, also known as training.\n",
    "2. Test set: This dataset consists of data the model has not previously encountered, akin to an exam. After using homework questions to learn the concepts (training), we evaluate how well the model has learned patterns and trends by presenting it with new, unseen questions.\n",
    "\n",
    "Ideally, we want a model that does well on both the training AND testing set.\n",
    "\n",
    "In the cell below, we split the data using the `train_test_split` method provided by `sklearn`. We allocate 80% of the data to the training set, and 20% of the data to the testing set (aka the exam).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZpRgK9WiBhc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4khUit2iG4D"
   },
   "source": [
    "---\n",
    "\n",
    "##### **Q4: Train a model on the train set, make predictions for both the train and test set, and report the accuracy on both sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ygJcwhrdvne"
   },
   "outputs": [],
   "source": [
    "## Complete the code below\n",
    "\n",
    "# create a model class\n",
    "\n",
    "# train model on the train set\n",
    "\n",
    "# make predictions for train set\n",
    "\n",
    "# make predictions for the test set\n",
    "\n",
    "# calculate accuracy for the train and test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8UmiT5mWpB8"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlrNZKY3mYCk"
   },
   "source": [
    "### Measures beyond Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd5nVsOElhGZ"
   },
   "source": [
    "While accuracy is a good measure of how many predictions the model is getting correct, we often care about the *type* of correct and incorrect predictions. More specifically, we care about True Positives, True Negatives, False Positives, and False Negatives:\n",
    "\n",
    "* False positive (FP): predicted positive, but the true label was actually negative. (Type I error)\n",
    "* False negative (FN): predicted negative, but the true label was actually positive. (Type II error)\n",
    "* True positive (TP): predicted positive, and the true label was indeed positive.\n",
    "* True negative (TN): predicted negative, and the true label was indeed negative.\n",
    "\n",
    "Using this terminology, we can improve our definition of Accuracy:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} =\\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XT1HP_XVQRHw"
   },
   "source": [
    "---\n",
    "##### **Q5: Calculate the True Positives, True Negatives, False Positives, and False negatives of your model predictions on the train set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPKxFzo-QcjV"
   },
   "outputs": [],
   "source": [
    "## Complete the code below\n",
    "\n",
    "# calculate each based on their descriptions above\n",
    "true_positive = ...\n",
    "true_negative = ...\n",
    "false_positive = ...\n",
    "false_negative = ...\n",
    "\n",
    "print(f\"True positives: {true_positive}\")\n",
    "print(f\"True negatives: {true_negative}\")\n",
    "print(f\"False positives: {false_positive}\")\n",
    "print(f\"False negatives: {false_negative}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY_KhxK6QcuG"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObQHbMgCQPDc"
   },
   "source": [
    "\n",
    "Apart from accuracy, other common ways to measure the performance of your classification model is *Precision* and *Recall.*\n",
    "\n",
    "\n",
    "In machine learning, \"precision\" refers to a metric that measures the **proportion of positive predictions made by a model that are actually correct**. This is basically asking \"What portion of people predicted to have diabetes actually have diabetes?\"\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBXkR62go7xl"
   },
   "source": [
    "\"Recall\" is a metric that measures how well a model can identify all relevant positive instances within a dataset. This is basically asking \"Of all the people that have diabetes, how many did the model actually predict.\"\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP+FN}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMC34GYrplRv"
   },
   "source": [
    "---\n",
    "\n",
    "##### **Q6: Calculate the train and test precision and recall of your model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hl-WIBOApkmc"
   },
   "outputs": [],
   "source": [
    "## Complete the code below\n",
    "\n",
    "# calculate each based on their descriptions above\n",
    "precision = ...\n",
    "recall = ...\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fPfjHoNpjuW"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTC3EnX7ko8H"
   },
   "source": [
    "## Graded Questions\n",
    "\n",
    "In this set of graded questions, you will train a Logistic Regression model on the Heart Failures dataset from the prior weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8noRpETlA1n"
   },
   "source": [
    "---\n",
    "\n",
    "##### **GQ1: Read in the heart failures dataset (`hf_data_tut.csv`) (1 mark) and split the predictor variables (features) from the labels (response variable) (1 mark).**\n",
    "\n",
    "> HINT: Look at your work from Week 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FF6eOB_hnwzY"
   },
   "outputs": [],
   "source": [
    "## Complete the code below\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# read in the data set\n",
    "hf_data = ...\n",
    "\n",
    "# separate the predictor variables and target variable\n",
    "y = ...\n",
    "x = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Gm5_C31nxAf"
   },
   "source": [
    "---\n",
    "##### **GQ2: Train a Logistic Regression model on *all* the data (1 mark). What is the accuracy (1 mark)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jDF8S4ToeqG"
   },
   "outputs": [],
   "source": [
    "## Complete the code below\n",
    "\n",
    "# create a model class\n",
    "model = ...\n",
    "# train model on the heart faliure dataset\n",
    "\n",
    "# make predictions for the heart faliure dataset\n",
    "predictions = ...\n",
    "# calculate accuracy for the heart faliure dataset\n",
    "accuracy = ...\n",
    "print(f\"Accuracy: {accuracy * 100:.4f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifOtJDeYoA15"
   },
   "source": [
    "---\n",
    "\n",
    "##### **GQ3: Split the dataset into a train and test set and retrain your model (1 mark). What is the train and test accuracy (2 marks), precision (2 marks), and recall (2 marks)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7RoqHGsodUS"
   },
   "outputs": [],
   "source": [
    "## Complete the code below\n",
    "\n",
    "# split the dataset into a train set and test set\n",
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "# train on the train set\n",
    "# create a model class\n",
    "model = ...\n",
    "# train the model\n",
    "\n",
    "# make predictions for the train and test set\n",
    "train_predictions = ...\n",
    "test_predictions = ...\n",
    "# calculate accuracy for the train and test set\n",
    "train_accuracy = ...\n",
    "test_accuracy = ...\n",
    "print(f\"Train accuracy: {train_accuracy * 100:.4f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.4f}%\")\n",
    "\n",
    "# calculate true_positive, true_negative, alse_positive, and false_negative for the test set\n",
    "\n",
    "# calculate precision and recall based on true_positive, true_negative, alse_positive, and false_negative\n",
    "precision = ...\n",
    "recall = ...\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this module, we introduced you to the fundamentals of training and evaluating a machine learning (ML) model.\n",
    "\n",
    "First, we introduced two primary supervised machine learning tasks: classification and regression. We then demonstrated how an ML model can learn rules and patterns in the data by iteratively making predictions and adjusting itself based on those predictions during the training process. A model's performance can be evaluated using various metrics, including accuracy, precision, and recall, which are best assessed on a dataset that is randomly split into training and testing sets.\n",
    "\n",
    "\n",
    "In the next module, we will explore additional models and deepen our understanding of how to apply machine learning to biological applications.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
