{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "oNkueaY_6xU3",
    "outputId": "ab0cd57a-c186-43cb-dbc2-b454ae19d74c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'texture_mean' converted to str data type\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517.0</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903.0</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301.0</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  radius_mean texture_mean  perimeter_mean  area_mean  \\\n",
       "0         NaN       NaN          NaN          NaN             NaN        NaN   \n",
       "1    842517.0         M        20.57        17.77          132.90     1326.0   \n",
       "2  84300903.0         M        19.69        21.25          130.00     1203.0   \n",
       "3  84348301.0         M        11.42        20.38           77.58      386.1   \n",
       "4  84358402.0         M          NaN        14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0              NaN               NaN             NaN                  NaN   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...            NaN              NaN         NaN               NaN   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0                NaN              NaN                   NaN             NaN   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                      NaN          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the original CSV\n",
    "data_path = \"bc_data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "\n",
    "# 1. Introduce incorrect data types (e.g., converting a numerical column to a string)\n",
    "numeric_columns = df.select_dtypes(include=np.number).columns\n",
    "if len(numeric_columns) > 0:\n",
    "    # Convert a numeric column to string type (introducing type inconsistency)\n",
    "    column_to_modify = numeric_columns[2]\n",
    "    df[column_to_modify] = df[column_to_modify].astype(str)\n",
    "    print(f\"Column '{column_to_modify}' converted to str data type\")\n",
    "\n",
    "# 2. Introduce missing values for entire rows\n",
    "nan_percentage = 0.05  # 10% of the data will be set to NaN\n",
    "nan_indices = np.random.choice(df.index, size=int(len(df) * nan_percentage), replace=False)\n",
    "df.loc[nan_indices, :] = np.nan\n",
    "\n",
    "# 3. Introduce missing values (randomly select rows and columns)\n",
    "num_nans = 10  # Set how many NaN values you want to introduce\n",
    "random_indices = np.random.choice(df.index, size=num_nans, replace=False)  # Random row indices\n",
    "random_columns = np.random.choice(df.columns, size=num_nans, replace=False)  # Random columns\n",
    "for idx, col in zip(random_indices, random_columns):\n",
    "    df.loc[idx, col] = np.nan\n",
    "\n",
    "# 4. Add duplicate rows (randomly choose some rows and append them to the DataFrame)\n",
    "duplicates = df.sample(frac=0.1, random_state=42)  # 10% of the data will be duplicated\n",
    "df = pd.concat([df, duplicates], ignore_index=True)\n",
    "\n",
    "# 5. Introduce noisy data (typos or irrelevant values in a categorical column)\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "if len(categorical_columns) > 0:\n",
    "    cat_column = categorical_columns[0]\n",
    "    noisy_indices = np.random.choice(df.index, size=5, replace=False)\n",
    "    df.loc[noisy_indices, cat_column] = ['WrongValue' for _ in noisy_indices]\n",
    "\n",
    "# Save the dirtified dataset to a new CSV for further use\n",
    "df.to_csv('bc_data_dirtified.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the dirtified dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RawK5p8w85mY",
    "outputId": "f6780fa8-4a7a-497f-f587-51b801939d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "Column 'texture_mean' has been incorrectly converted to string.\n",
      "\n",
      "2. Number of rows with all NaN values: 30\n",
      "\n",
      "3. Total NaN values in the DataFrame: 1596\n",
      "\n",
      "4. Number of duplicated rows (excluding the first occurrence): 82\n",
      "\n",
      "5. Occurrences of 'WrongValue' in categorical columns:\n",
      "id                         0\n",
      "diagnosis                  5\n",
      "radius_mean                0\n",
      "texture_mean               0\n",
      "perimeter_mean             0\n",
      "area_mean                  0\n",
      "smoothness_mean            0\n",
      "compactness_mean           0\n",
      "concavity_mean             0\n",
      "concave points_mean        0\n",
      "symmetry_mean              0\n",
      "fractal_dimension_mean     0\n",
      "radius_se                  0\n",
      "texture_se                 0\n",
      "perimeter_se               0\n",
      "area_se                    0\n",
      "smoothness_se              0\n",
      "compactness_se             0\n",
      "concavity_se               0\n",
      "concave points_se          0\n",
      "symmetry_se                0\n",
      "fractal_dimension_se       0\n",
      "radius_worst               0\n",
      "texture_worst              0\n",
      "perimeter_worst            0\n",
      "area_worst                 0\n",
      "smoothness_worst           0\n",
      "compactness_worst          0\n",
      "concavity_worst            0\n",
      "concave points_worst       0\n",
      "symmetry_worst             0\n",
      "fractal_dimension_worst    0\n",
      "Unnamed: 32                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Check for incorrect data types (numeric columns converted to string)\n",
    "print(\"1.\")\n",
    "string_columns = df.select_dtypes(include=['object']).columns\n",
    "for col in numeric_columns:\n",
    "    if col in string_columns:\n",
    "        print(f\"Column '{col}' has been incorrectly converted to string.\")\n",
    "\n",
    "# 2.  Check if any row has all NaN values\n",
    "nan_rows = df[df.isna().all(axis=1)]\n",
    "print(f\"\\n2. Number of rows with all NaN values: {len(nan_rows)}\")\n",
    "\n",
    "# 3. Count total NaN values in the DataFrame\n",
    "total_nans = df.isna().sum().sum()\n",
    "print(f\"\\n3. Total NaN values in the DataFrame: {total_nans}\")\n",
    "\n",
    "# 4. Check for duplicated rows\n",
    "duplicates = df[df.duplicated()]\n",
    "print(f\"\\n4. Number of duplicated rows (excluding the first occurrence): {len(duplicates)}\")\n",
    "\n",
    "# 5. Check for noisy data ('WrongValue' in categorical columns)\n",
    "noisy_data_check = df.isin(['WrongValue']).sum()\n",
    "print(\"\\n5. Occurrences of 'WrongValue' in categorical columns:\")\n",
    "print(noisy_data_check)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfqn2YMCBP4Q",
    "outputId": "e15d5848-d8c4-4f5a-f917-8ab257923eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file zipped to: /content/data/thyroid_cancer_risk_data_dirtified.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Zip the CSV file\n",
    "zip_file_path = '/content/data/thyroid_cancer_risk_data_dirtified.zip'\n",
    "csv_file_path = '/content/data/thyroid_cancer_risk_data_dirtified.csv'\n",
    "with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    zipf.write(csv_file_path, arcname='thyroid_cancer_risk_data_dirtified.csv')\n",
    "\n",
    "print(f\"CSV file zipped to: {zip_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
